import numpy as np
import pymongo
import pandas as pd
import os
import tempfile
from sklearn.preprocessing import LabelEncoder
from azure.storage.blob import BlockBlobService
from dotenv import load_dotenv
load_dotenv()

def get_values_array_fields(row, column_name):
    if column_name in row.keys() and len(row[column_name]) != 0:
        row[column_name] = ','.join(map(str, row[column_name]))
    else:
        row[column_name] = np.NaN
    return row


# Encoding the age using the range
def encoding_user_age(df):
    df.loc[df['userAge'].between(0, 18), 'age'] = 0
    df.loc[df['userAge'].between(19, 24), 'age'] = 1
    df.loc[df['userAge'].between(25, 34), 'age'] = 2
    df.loc[df['userAge'].between(35, 44), 'age'] = 3
    df.loc[df['userAge'].between(45, 54), 'age'] = 4
    df.loc[df['userAge'].between(55, 64), 'age'] = 5
    df.loc[df['userAge'].gt(64), 'age'] = 6
    df.drop(['userAge'], axis=1, inplace=True)
    df.rename(columns={'age': 'userAge'}, inplace=True)
    return df


# One hot encoding the input features
def one_hot_encodings(dataset, column_name):
    df_column = pd.DataFrame(dataset[column_name].fillna("0").tolist())
    df_stack = df_column.stack()
    df_dummies = pd.get_dummies(df_stack)
    encoded_df = df_dummies.groupby(level=0).sum()
    encoded_df.drop(['0'], inplace=True, axis=1)
    concat_df = pd.concat([dataset, encoded_df], axis=1)
    concat_df.drop([column_name], inplace=True, axis=1)
    return concat_df


# uploading the data in the blob storage:
def upload_data(data):
    block_blob_service = BlockBlobService(
        account_name=os.getenv('azurestorageaccountname'),
        account_key=os.getenv('azurestorageaccountkey')
    )
    local_path = os.path.expanduser("/tmp/")
    full_path_to_file = os.path.join(local_path,"lookalike-data.xz")
    data.to_csv(full_path_to_file, index=False, compression='xz')
    az_blob_name = "lookalike-data.xz"
    az_container_name = f"{os.getenv('containername')}/{os.getenv('BUSINESS_CLIENT')}/lookalike"
    block_blob_service.create_blob_from_path(az_container_name, az_blob_name, full_path_to_file)


def data_extraction():
    client = pymongo.MongoClient(os.getenv('DB_URI'))
    db = client[os.getenv('DB_NAME')]
    col_client = db["clients"]

    # query function getting the data from the different collection
    client_columns = {'_id': 1, 'leads': 1, 'presenceCoordinates': 1, 'userCompanyName': 1, 'userIncome': 1,
                      'deviceTypes': 1, 'audiences': 1, 'userSex': 1, 'userAge': 1, 'createdAt': 1, 'locations': 1,
                      'timestamp': 1, 'tags': 1, 'marketingChannels': 1, 'userIndustry': 1, 'campaigns': 1,
                      'userFamilyDetails': 1, 'userChildren': 1, 'userStudies': 1, 'city_location.location': 1,
                      'counties_location.location': 1, 'business_location.coords': 1,
                      'action_data': 1, 'tag_name': 1}

    results = col_client.aggregate([
        {
            '$lookup': {
                'from': 'cities',
                'localField': 'userCityId',
                'foreignField': '_id',
                'as': 'city_location'
            }
        },
        {
            '$lookup': {
                'from': 'counties',
                'localField': 'userCountyId',
                'foreignField': '_id',
                'as': 'counties_location'
            }
        },
        {
            '$lookup': {
                'from': 'locations',
                'localField': 'locations',
                'foreignField': '_id',
                'as': 'business_location'
            }
        },
        {
            '$lookup': {
                'from': 'actions',
                'localField': '_id',
                'foreignField': 'clientId',
                'as': 'action_data'
            }
        },
        {
            '$project': client_columns
        }
    ])

    client_list = []
    for row in results:
        # Getting number of leads generated by each client
        if 'leads' in row.keys():
            row['no_of_leads'] = len(row['leads'])

        # Getting the audiences form the client collections
        row['audiences'] = ','.join(map(str, row['audiences'])) if 'audiences' in row.keys() and len(row['audiences']) \
                                                                   != 0 else np.NaN
        # Getting the deviceTypes form the client collection
        row = get_values_array_fields(row, 'deviceTypes')

        # Getting the campaigns form the client collection
        row = get_values_array_fields(row, 'campaigns')

        # Extracting the TAGS fom the client collection:
        if 'tags' in row.keys() and len(row['tags']) != 0:
            tag_list = []
            for tag in row['tags']:
                tag_list.append(str(tag['_id']))
            tag_str = ",".join(map(str, tag_list))
            row['tags'] = tag_str
        else:
            row['tags'] = np.NaN

        # Marketing Channels for each client
        list_channel = []
        if 'marketingChannels' in row.keys() and len(row['marketingChannels']) != 0:
            for channels in row['marketingChannels'][-1]['settings']:
                if channels['agreed']:
                    channel = channels['channel'] + '_' + channels['type']
                    list_channel.append(channel)
            if len(list_channel) != 0:
                row['marketingChannels'] = ",".join(map(str, list_channel))
            else:
                row['marketingChannels'] = np.NaN
        else:
            row['marketingChannels'] = np.NaN

        # Getting the Geo coordination for each client and fill the null values based on the location id
        if 'presenceCoordinates' in row.keys() and len(row['presenceCoordinates']) != 0:
            row["geo_location_lat"] = row['presenceCoordinates'][0]['coordinates']['lat']
            row["geo_location_long"] = row['presenceCoordinates'][0]['coordinates']['long']

        elif len(row["city_location"]) != 0:
            city_location = row["city_location"][0]
            row["geo_location_lat"] = city_location["location"]['coordinates'][0]
            row["geo_location_long"] = city_location["location"]['coordinates'][1]

        elif len(row["counties_location"]) != 0 and len(row["counties_location"][0]["location"]['coordinates']) != 0:
            counties_location = row["counties_location"][0]
            row["geo_location_lat"] = counties_location["location"]['coordinates'][0]
            row["geo_location_long"] = counties_location["location"]['coordinates'][1]

        elif len(row["business_location"]) != 0:
            location = row['business_location'][-1]
            row["geo_location_lat"] = location['coords'][0]
            row["geo_location_long"] = location['coords'][1]

        else:
            row["geo_location_lat"] = np.NaN
            row["geo_location_long"] = np.NaN

        # Getting the data from action collection

        view, totaltime, rating = 0, 0, 0
        for action in row['action_data']:
            if action["aditionalData"] != None:
                if action['actionType'] == 'visit' and 'views' in action['aditionalData']:
                    view = view + action['aditionalData']['views']
                if action['actionType'] == 'visit' and 'totalTime' in action['aditionalData']:
                    totaltime = totaltime + action['aditionalData']['totalTime']
                if action['actionType'] == 'feedback' and "rating" in action['aditionalData']:
                    rating = rating + action['aditionalData']['rating']
        row["frequency_visit"] = view
        row["duration_visit"] = totaltime
        row["rating"] = rating
        client_list.append(row)

    client_df = pd.DataFrame(client_list)
    client_df.drop(['action_data', 'city_location', 'counties_location', 'business_location', 'presenceCoordinates',
                    'locations', 'leads'], inplace=True, axis=1)

    # Removing the user that are have null values in the geo_location columns.
    client_df = client_df[(client_df['geo_location_lat'].notnull())].copy()
    client_df.reset_index(inplace=True, drop=True)

    # Removing the user that are have null values in the audiences columns.
    client_df = client_df[(client_df['audiences'].notnull())].copy()
    client_df.reset_index(inplace=True, drop=True)

    # Applying one-hot encoding to the marketingChannels , deviceTypes, tag columns.
    client_df['tags'].fillna('0', inplace=True)
    client_df['tags'] = client_df['tags'].apply(lambda x: x.split(","))
    client_df = one_hot_encodings(client_df, 'tags')

    client_df['marketingChannels'].fillna('0', inplace=True)
    client_df['marketingChannels'] = client_df['marketingChannels'].apply(lambda x: x.split(","))
    client_df = one_hot_encodings(client_df, 'marketingChannels')

    client_df['deviceTypes'].fillna('0', inplace=True)
    client_df['deviceTypes'] = client_df['deviceTypes'].apply(lambda x: x.split(","))
    client_df = one_hot_encodings(client_df, 'deviceTypes')

    client_df['campaigns'].fillna('0', inplace=True)
    client_df['campaigns'] = client_df['campaigns'].apply(lambda x: x.split(","))
    client_df = one_hot_encodings(client_df, 'campaigns')

    # Encoding the user age.
    client_df = encoding_user_age(client_df)

    # Applying the label encoding.
    le = LabelEncoder()
    client_df.replace('', np.NaN, inplace=True)
    client_df['userIndustry'].fillna('nan', inplace=True)
    client_df['userCompanyName'].fillna('nan', inplace=True)
    client_df['userStudies'].fillna('nan', inplace=True)
    client_df['userCompanyName'] = le.fit_transform(client_df['userCompanyName'])
    client_df['userIndustry'] = le.fit_transform(client_df['userIndustry'])
    client_df['userStudies'] = le.fit_transform(client_df['userStudies'])
    client_df['userSex'] = client_df['userSex'].map({"male": 1, "female": 2, "others": 3})
    client_df['userFamilyDetails'] = client_df['userFamilyDetails'].map({"single": 1, "married": 2})

    # Calculating the active days of each client.
    client_df['createdAt'] = pd.to_datetime(client_df['createdAt'], errors='coerce')
    client_df['timestamp'] = pd.to_datetime(client_df['timestamp'], errors='coerce')
    client_df['active_days'] = client_df['timestamp'] - client_df['createdAt']
    client_df['active_days'] = client_df['active_days'].dt.days
    client_df.drop(['createdAt', 'timestamp'], inplace=True, axis=1)
    upload_data(client_df)


if __name__=="__main__":
    data_extraction()

